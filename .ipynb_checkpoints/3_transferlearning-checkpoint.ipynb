{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:16.510216Z",
     "iopub.status.busy": "2023-07-22T06:38:16.509846Z",
     "iopub.status.idle": "2023-07-22T06:38:29.124382Z",
     "shell.execute_reply": "2023-07-22T06:38:29.122862Z",
     "shell.execute_reply.started": "2023-07-22T06:38:16.510186Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:29.128079Z",
     "iopub.status.busy": "2023-07-22T06:38:29.127719Z",
     "iopub.status.idle": "2023-07-22T06:38:44.415769Z",
     "shell.execute_reply": "2023-07-22T06:38:44.414824Z",
     "shell.execute_reply.started": "2023-07-22T06:38:29.128050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed \n",
    "\n",
    "from transformers import GenerationConfig\n",
    "from torch.optim import AdamW\n",
    "# from transformers import get_scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data, toeknizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:44.417888Z",
     "iopub.status.busy": "2023-07-22T06:38:44.417565Z",
     "iopub.status.idle": "2023-07-22T06:38:44.474824Z",
     "shell.execute_reply": "2023-07-22T06:38:44.473874Z",
     "shell.execute_reply.started": "2023-07-22T06:38:44.417856Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/pre-processed-data/train_preprocessed.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/pre-processed-data/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:44.485791Z",
     "iopub.status.busy": "2023-07-22T06:38:44.485500Z",
     "iopub.status.idle": "2023-07-22T06:38:44.505789Z",
     "shell.execute_reply": "2023-07-22T06:38:44.504899Z",
     "shell.execute_reply.started": "2023-07-22T06:38:44.485766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>us</td>\n",
       "      <td>Our Deeds Reason earthquake May ALLAH Forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire</td>\n",
       "      <td>canada</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>nowhere</td>\n",
       "      <td>All residents asked shelter place notified off...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>california</td>\n",
       "      <td>people receive wildfires evacuation orders Cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoke</td>\n",
       "      <td>nowhere</td>\n",
       "      <td>Just got sent photo Ruby Alaska smoke wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword    location                                               text  \\\n",
       "0     neutral          us   Our Deeds Reason earthquake May ALLAH Forgive us   \n",
       "1        fire      canada              Forest fire near La Ronge Sask Canada   \n",
       "2  evacuation     nowhere  All residents asked shelter place notified off...   \n",
       "3  evacuation  california  people receive wildfires evacuation orders Cal...   \n",
       "4       smoke     nowhere  Just got sent photo Ruby Alaska smoke wildfire...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:45.270594Z",
     "iopub.status.busy": "2023-07-22T06:38:45.269859Z",
     "iopub.status.idle": "2023-07-22T06:38:45.304097Z",
     "shell.execute_reply": "2023-07-22T06:38:45.302922Z",
     "shell.execute_reply.started": "2023-07-22T06:38:45.270559Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:45.985844Z",
     "iopub.status.busy": "2023-07-22T06:38:45.985483Z",
     "iopub.status.idle": "2023-07-22T06:38:46.009972Z",
     "shell.execute_reply": "2023-07-22T06:38:46.009024Z",
     "shell.execute_reply.started": "2023-07-22T06:38:45.985814Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:50.370776Z",
     "iopub.status.busy": "2023-07-22T06:38:50.369770Z",
     "iopub.status.idle": "2023-07-22T06:38:50.378074Z",
     "shell.execute_reply": "2023-07-22T06:38:50.376571Z",
     "shell.execute_reply.started": "2023-07-22T06:38:50.370733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['keyword', 'location', 'text', 'target'],\n",
       "    num_rows: 7613\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:51.325948Z",
     "iopub.status.busy": "2023-07-22T06:38:51.325594Z",
     "iopub.status.idle": "2023-07-22T06:38:51.330898Z",
     "shell.execute_reply": "2023-07-22T06:38:51.329745Z",
     "shell.execute_reply.started": "2023-07-22T06:38:51.325919Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = \"facebook/bart-large-cnn\"  # accuracy .824988\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:52.722641Z",
     "iopub.status.busy": "2023-07-22T06:38:52.721734Z",
     "iopub.status.idle": "2023-07-22T06:38:54.528982Z",
     "shell.execute_reply": "2023-07-22T06:38:54.527984Z",
     "shell.execute_reply.started": "2023-07-22T06:38:52.722610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9964be092ee245e5b07b0bd1b711f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c134bbff71144ff9ce1110679446fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921e5d645d484146abcfb07a026d1482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5980bf1c5f1d4e8788fb94a4adc56712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:57.441019Z",
     "iopub.status.busy": "2023-07-22T06:38:57.440349Z",
     "iopub.status.idle": "2023-07-22T06:38:57.446485Z",
     "shell.execute_reply": "2023-07-22T06:38:57.445511Z",
     "shell.execute_reply.started": "2023-07-22T06:38:57.440987Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"Not Disaster\", 1: \"Disaster\"}\n",
    "label2id = {\"Not Disaster\": 0, \"Disaster\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:38:58.500837Z",
     "iopub.status.busy": "2023-07-22T06:38:58.500484Z",
     "iopub.status.idle": "2023-07-22T06:39:10.107747Z",
     "shell.execute_reply": "2023-07-22T06:39:10.106729Z",
     "shell.execute_reply.started": "2023-07-22T06:38:58.500810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074233e94f074b8e9a30b576de47022f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:10.110244Z",
     "iopub.status.busy": "2023-07-22T06:39:10.109862Z",
     "iopub.status.idle": "2023-07-22T06:39:10.119647Z",
     "shell.execute_reply": "2023-07-22T06:39:10.118616Z",
     "shell.execute_reply.started": "2023-07-22T06:39:10.110211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForSequenceClassification(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): BartClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:10.121742Z",
     "iopub.status.busy": "2023-07-22T06:39:10.120879Z",
     "iopub.status.idle": "2023-07-22T06:39:11.043330Z",
     "shell.execute_reply": "2023-07-22T06:39:11.042340Z",
     "shell.execute_reply.started": "2023-07-22T06:39:10.121708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e7d8e62640404fb9d8906e8078a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75b5f8398e74e75b8ada5ebec133afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_example(example):\n",
    "    return tokenizer(example[\"text\"], example[\"keyword\"], truncation=True)\n",
    "\n",
    "tokenized_train_data = train_ds.map(tokenize_example, batched=True)\n",
    "tokenized_test_data = test_ds.map(tokenize_example, batched=True, remove_columns = test_ds.column_names)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:11.046210Z",
     "iopub.status.busy": "2023-07-22T06:39:11.045580Z",
     "iopub.status.idle": "2023-07-22T06:39:11.053052Z",
     "shell.execute_reply": "2023-07-22T06:39:11.052065Z",
     "shell.execute_reply.started": "2023-07-22T06:39:11.046173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['keyword', 'location', 'text', 'target', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 7613\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:11.055048Z",
     "iopub.status.busy": "2023-07-22T06:39:11.054345Z",
     "iopub.status.idle": "2023-07-22T06:39:11.069053Z",
     "shell.execute_reply": "2023-07-22T06:39:11.067976Z",
     "shell.execute_reply.started": "2023-07-22T06:39:11.055015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'labels': Value(dtype='int64', id=None),\n",
       "  'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       "  'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)},\n",
       " {'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       "  'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data = tokenized_train_data.remove_columns([\"keyword\", \"location\", \"text\"])\n",
    "tokenized_train_data = tokenized_train_data.rename_column(\"target\", \"labels\")\n",
    "tokenized_train_data.set_format(\"torch\")\n",
    "tokenized_test_data.set_format(\"torch\")\n",
    "tokenized_train_data.features, tokenized_test_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:11.070906Z",
     "iopub.status.busy": "2023-07-22T06:39:11.070445Z",
     "iopub.status.idle": "2023-07-22T06:39:11.086020Z",
     "shell.execute_reply": "2023-07-22T06:39:11.085133Z",
     "shell.execute_reply.started": "2023-07-22T06:39:11.070874Z"
    }
   },
   "outputs": [],
   "source": [
    "train_val_split = tokenized_train_data.train_test_split(0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:12.398765Z",
     "iopub.status.busy": "2023-07-22T06:39:12.397642Z",
     "iopub.status.idle": "2023-07-22T06:39:12.410054Z",
     "shell.execute_reply": "2023-07-22T06:39:12.409069Z",
     "shell.execute_reply.started": "2023-07-22T06:39:12.398729Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_val_split[\"train\"], shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    train_val_split[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_test_data, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:14.473738Z",
     "iopub.status.busy": "2023-07-22T06:39:14.473041Z",
     "iopub.status.idle": "2023-07-22T06:39:15.114090Z",
     "shell.execute_reply": "2023-07-22T06:39:15.113130Z",
     "shell.execute_reply.started": "2023-07-22T06:39:14.473702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 7613\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:16.128876Z",
     "iopub.status.busy": "2023-07-22T06:39:16.128512Z",
     "iopub.status.idle": "2023-07-22T06:39:16.174992Z",
     "shell.execute_reply": "2023-07-22T06:39:16.174040Z",
     "shell.execute_reply.started": "2023-07-22T06:39:16.128846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([64]),\n",
       " 'input_ids': torch.Size([64, 37]),\n",
       " 'attention_mask': torch.Size([64, 37])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:17.255389Z",
     "iopub.status.busy": "2023-07-22T06:39:17.254197Z",
     "iopub.status.idle": "2023-07-22T06:39:18.128635Z",
     "shell.execute_reply": "2023-07-22T06:39:18.127749Z",
     "shell.execute_reply.started": "2023-07-22T06:39:17.255346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d93178cff74a0d99cc4666d3947b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Use np.argmax to get the predicted class indices from logits\n",
    "    predictions = np.argmax(predictions[0], axis=1)\n",
    "    \n",
    "\n",
    "    # If the labels are one-hot encoded, convert them to class indices\n",
    "    if len(labels.shape) > 1:\n",
    "        labels = np.argmax(labels, axis=-1)\n",
    "\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:39:25.366132Z",
     "iopub.status.busy": "2023-07-22T06:39:25.364997Z",
     "iopub.status.idle": "2023-07-22T06:45:52.213816Z",
     "shell.execute_reply": "2023-07-22T06:45:52.212698Z",
     "shell.execute_reply.started": "2023-07-22T06:39:25.366070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230722_063957-ok9n16vm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skt27182/huggingface/runs/ok9n16vm' target=\"_blank\">effortless-vortex-20</a></strong> to <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">https://wandb.ai/skt27182/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skt27182/huggingface/runs/ok9n16vm' target=\"_blank\">https://wandb.ai/skt27182/huggingface/runs/ok9n16vm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 05:21, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.422167</td>\n",
       "      <td>0.832540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471608</td>\n",
       "      <td>0.823182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.792110</td>\n",
       "      <td>0.810868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.809628</td>\n",
       "      <td>0.815630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=384, training_loss=0.2833700974782308, metrics={'train_runtime': 381.4265, 'train_samples_per_second': 15.961, 'train_steps_per_second': 1.007, 'total_flos': 407560594679904.0, 'train_loss': 0.2833700974782308, 'epoch': 4.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_val_split[\"train\"],\n",
    "    eval_dataset=train_val_split[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:45:52.217322Z",
     "iopub.status.busy": "2023-07-22T06:45:52.216072Z",
     "iopub.status.idle": "2023-07-22T06:46:21.645100Z",
     "shell.execute_reply": "2023-07-22T06:46:21.641574Z",
     "shell.execute_reply.started": "2023-07-22T06:45:52.217283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949fff82eeba4435909aa2342a331b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8325398128386143}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load( \"accuracy\")\n",
    "\n",
    "base_model.eval()\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(base_model.parameters(), lr=2e-05)\n",
    "\n",
    "# num_epochs = 10\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# lr_scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0, total_iters=num_training_steps)\n",
    "\n",
    "# print(num_training_steps)\n",
    "\n",
    "# base_model.to(device)\n",
    "\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# base_model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         outputs = base_model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         progress_bar.set_postfix(loss=loss.item())\n",
    "#         progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:46:59.185804Z",
     "iopub.status.busy": "2023-07-22T06:46:59.185341Z",
     "iopub.status.idle": "2023-07-22T06:47:14.700054Z",
     "shell.execute_reply": "2023-07-22T06:47:14.698878Z",
     "shell.execute_reply.started": "2023-07-22T06:46:59.185762Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = []\n",
    "\n",
    "base_model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    pred.append(predictions.reshape(-1).cpu().numpy())\n",
    "\n",
    "# Convert the list of arrays into a 1D NumPy array\n",
    "pred = np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:47:14.702725Z",
     "iopub.status.busy": "2023-07-22T06:47:14.702067Z",
     "iopub.status.idle": "2023-07-22T06:47:14.714308Z",
     "shell.execute_reply": "2023-07-22T06:47:14.713317Z",
     "shell.execute_reply.started": "2023-07-22T06:47:14.702683Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:47:14.716568Z",
     "iopub.status.busy": "2023-07-22T06:47:14.715878Z",
     "iopub.status.idle": "2023-07-22T06:47:14.752523Z",
     "shell.execute_reply": "2023-07-22T06:47:14.750741Z",
     "shell.execute_reply.started": "2023-07-22T06:47:14.716532Z"
    }
   },
   "outputs": [],
   "source": [
    "ids = pd.read_csv('/kaggle/input/test-id/test_id.csv')['id']\n",
    "\n",
    "# merge ids and predictions\n",
    "submission = pd.DataFrame(np.concatenate((ids.values.reshape(-1, 1), y_pred.reshape(-1,1)), axis=1), columns=['id', 'target'])\n",
    "\n",
    "# make id int   \n",
    "submission['id'] = submission['id'].astype('int')\n",
    "\n",
    "# make target 0 and 1\n",
    "submission['target'] = submission['target'].apply(lambda x: 0 if x < 0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:47:14.755232Z",
     "iopub.status.busy": "2023-07-22T06:47:14.754650Z",
     "iopub.status.idle": "2023-07-22T06:47:14.769456Z",
     "shell.execute_reply": "2023-07-22T06:47:14.768493Z",
     "shell.execute_reply.started": "2023-07-22T06:47:14.755198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:47:14.771492Z",
     "iopub.status.busy": "2023-07-22T06:47:14.770809Z",
     "iopub.status.idle": "2023-07-22T06:47:15.823746Z",
     "shell.execute_reply": "2023-07-22T06:47:15.822390Z",
     "shell.execute_reply.started": "2023-07-22T06:47:14.771460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "rm: cannot remove '/kaggle/working/submission.csv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rm /kaggle/working/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T06:47:15.832021Z",
     "iopub.status.busy": "2023-07-22T06:47:15.825780Z",
     "iopub.status.idle": "2023-07-22T06:47:15.852517Z",
     "shell.execute_reply": "2023-07-22T06:47:15.851363Z",
     "shell.execute_reply.started": "2023-07-22T06:47:15.831982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
