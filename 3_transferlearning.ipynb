{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"!pip -q install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:16.509846Z","iopub.execute_input":"2023-07-22T06:38:16.510216Z","iopub.status.idle":"2023-07-22T06:38:29.124382Z","shell.execute_reply.started":"2023-07-22T06:38:16.510186Z","shell.execute_reply":"2023-07-22T06:38:29.122862Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\n\nimport datasets\nimport torch\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n\nfrom transformers import TrainingArguments, Trainer\nimport evaluate\n\n\nfrom accelerate import Accelerator\nfrom accelerate.utils import set_seed \n\nfrom transformers import GenerationConfig\nfrom torch.optim import AdamW\n# from transformers import get_scheduler\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-22T06:38:29.127719Z","iopub.execute_input":"2023-07-22T06:38:29.128079Z","iopub.status.idle":"2023-07-22T06:38:44.415769Z","shell.execute_reply.started":"2023-07-22T06:38:29.128050Z","shell.execute_reply":"2023-07-22T06:38:44.414824Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# load data, toeknizer and model","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/pre-processed-data/train_preprocessed.csv')\ntest_df = pd.read_csv('/kaggle/input/pre-processed-data/test_preprocessed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:44.417565Z","iopub.execute_input":"2023-07-22T06:38:44.417888Z","iopub.status.idle":"2023-07-22T06:38:44.474824Z","shell.execute_reply.started":"2023-07-22T06:38:44.417856Z","shell.execute_reply":"2023-07-22T06:38:44.473874Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:44.485500Z","iopub.execute_input":"2023-07-22T06:38:44.485791Z","iopub.status.idle":"2023-07-22T06:38:44.505789Z","shell.execute_reply.started":"2023-07-22T06:38:44.485766Z","shell.execute_reply":"2023-07-22T06:38:44.504899Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      keyword    location                                               text  \\\n0     neutral          us   Our Deeds Reason earthquake May ALLAH Forgive us   \n1        fire      canada              Forest fire near La Ronge Sask Canada   \n2  evacuation     nowhere  All residents asked shelter place notified off...   \n3  evacuation  california  people receive wildfires evacuation orders Cal...   \n4       smoke     nowhere  Just got sent photo Ruby Alaska smoke wildfire...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>us</td>\n      <td>Our Deeds Reason earthquake May ALLAH Forgive us</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fire</td>\n      <td>canada</td>\n      <td>Forest fire near La Ronge Sask Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>evacuation</td>\n      <td>nowhere</td>\n      <td>All residents asked shelter place notified off...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>evacuation</td>\n      <td>california</td>\n      <td>people receive wildfires evacuation orders Cal...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>smoke</td>\n      <td>nowhere</td>\n      <td>Just got sent photo Ruby Alaska smoke wildfire...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:45.269859Z","iopub.execute_input":"2023-07-22T06:38:45.270594Z","iopub.status.idle":"2023-07-22T06:38:45.304097Z","shell.execute_reply.started":"2023-07-22T06:38:45.270559Z","shell.execute_reply":"2023-07-22T06:38:45.302922Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:45.985483Z","iopub.execute_input":"2023-07-22T06:38:45.985844Z","iopub.status.idle":"2023-07-22T06:38:46.009972Z","shell.execute_reply.started":"2023-07-22T06:38:45.985814Z","shell.execute_reply":"2023-07-22T06:38:46.009024Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:50.369770Z","iopub.execute_input":"2023-07-22T06:38:50.370776Z","iopub.status.idle":"2023-07-22T06:38:50.378074Z","shell.execute_reply.started":"2023-07-22T06:38:50.370733Z","shell.execute_reply":"2023-07-22T06:38:50.376571Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['keyword', 'location', 'text', 'target'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = \"facebook/bart-large-cnn\"  # accuracy .824988\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:51.325594Z","iopub.execute_input":"2023-07-22T06:38:51.325948Z","iopub.status.idle":"2023-07-22T06:38:51.330898Z","shell.execute_reply.started":"2023-07-22T06:38:51.325919Z","shell.execute_reply":"2023-07-22T06:38:51.329745Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:52.721734Z","iopub.execute_input":"2023-07-22T06:38:52.722641Z","iopub.status.idle":"2023-07-22T06:38:54.528982Z","shell.execute_reply.started":"2023-07-22T06:38:52.722610Z","shell.execute_reply":"2023-07-22T06:38:54.527984Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9964be092ee245e5b07b0bd1b711f3b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c134bbff71144ff9ce1110679446fc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"921e5d645d484146abcfb07a026d1482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5980bf1c5f1d4e8788fb94a4adc56712"}},"metadata":{}}]},{"cell_type":"code","source":"id2label = {0: \"Not Disaster\", 1: \"Disaster\"}\nlabel2id = {\"Not Disaster\": 0, \"Disaster\": 1}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:57.440349Z","iopub.execute_input":"2023-07-22T06:38:57.441019Z","iopub.status.idle":"2023-07-22T06:38:57.446485Z","shell.execute_reply.started":"2023-07-22T06:38:57.440987Z","shell.execute_reply":"2023-07-22T06:38:57.445511Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"base_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:38:58.500484Z","iopub.execute_input":"2023-07-22T06:38:58.500837Z","iopub.status.idle":"2023-07-22T06:39:10.107747Z","shell.execute_reply.started":"2023-07-22T06:38:58.500810Z","shell.execute_reply":"2023-07-22T06:39:10.106729Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"074233e94f074b8e9a30b576de47022f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:10.109862Z","iopub.execute_input":"2023-07-22T06:39:10.110244Z","iopub.status.idle":"2023-07-22T06:39:10.119647Z","shell.execute_reply.started":"2023-07-22T06:39:10.110211Z","shell.execute_reply":"2023-07-22T06:39:10.118616Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"BartForSequenceClassification(\n  (model): BartModel(\n    (shared): Embedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (classification_head): BartClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def tokenize_example(example):\n    return tokenizer(example[\"text\"], example[\"keyword\"], truncation=True)\n\ntokenized_train_data = train_ds.map(tokenize_example, batched=True)\ntokenized_test_data = test_ds.map(tokenize_example, batched=True, remove_columns = test_ds.column_names)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:10.120879Z","iopub.execute_input":"2023-07-22T06:39:10.121742Z","iopub.status.idle":"2023-07-22T06:39:11.043330Z","shell.execute_reply.started":"2023-07-22T06:39:10.121708Z","shell.execute_reply":"2023-07-22T06:39:11.042340Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e7d8e62640404fb9d8906e8078a6da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75b5f8398e74e75b8ada5ebec133afd"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train_data","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:11.045580Z","iopub.execute_input":"2023-07-22T06:39:11.046210Z","iopub.status.idle":"2023-07-22T06:39:11.053052Z","shell.execute_reply.started":"2023-07-22T06:39:11.046173Z","shell.execute_reply":"2023-07-22T06:39:11.052065Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['keyword', 'location', 'text', 'target', 'input_ids', 'attention_mask'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train_data = tokenized_train_data.remove_columns([\"keyword\", \"location\", \"text\"])\ntokenized_train_data = tokenized_train_data.rename_column(\"target\", \"labels\")\ntokenized_train_data.set_format(\"torch\")\ntokenized_test_data.set_format(\"torch\")\ntokenized_train_data.features, tokenized_test_data.features","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:11.054345Z","iopub.execute_input":"2023-07-22T06:39:11.055048Z","iopub.status.idle":"2023-07-22T06:39:11.069053Z","shell.execute_reply.started":"2023-07-22T06:39:11.055015Z","shell.execute_reply":"2023-07-22T06:39:11.067976Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"({'labels': Value(dtype='int64', id=None),\n  'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n  'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)},\n {'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n  'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)})"},"metadata":{}}]},{"cell_type":"code","source":"train_val_split = tokenized_train_data.train_test_split(0.8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:11.070445Z","iopub.execute_input":"2023-07-22T06:39:11.070906Z","iopub.status.idle":"2023-07-22T06:39:11.086020Z","shell.execute_reply.started":"2023-07-22T06:39:11.070874Z","shell.execute_reply":"2023-07-22T06:39:11.085133Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    train_val_split[\"train\"], shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n)\neval_dataloader = DataLoader(\n    train_val_split[\"test\"], batch_size=BATCH_SIZE, collate_fn=data_collator\n)\n\ntest_dataloader = DataLoader(\n    tokenized_test_data, batch_size=BATCH_SIZE, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:12.397642Z","iopub.execute_input":"2023-07-22T06:39:12.398765Z","iopub.status.idle":"2023-07-22T06:39:12.410054Z","shell.execute_reply.started":"2023-07-22T06:39:12.398729Z","shell.execute_reply":"2023-07-22T06:39:12.409069Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_train_data","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:14.473041Z","iopub.execute_input":"2023-07-22T06:39:14.473738Z","iopub.status.idle":"2023-07-22T06:39:15.114090Z","shell.execute_reply.started":"2023-07-22T06:39:14.473702Z","shell.execute_reply":"2023-07-22T06:39:15.113130Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"for batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:16.128512Z","iopub.execute_input":"2023-07-22T06:39:16.128876Z","iopub.status.idle":"2023-07-22T06:39:16.174992Z","shell.execute_reply.started":"2023-07-22T06:39:16.128846Z","shell.execute_reply":"2023-07-22T06:39:16.174040Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'labels': torch.Size([64]),\n 'input_ids': torch.Size([64, 37]),\n 'attention_mask': torch.Size([64, 37])}"},"metadata":{}}]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\n\n\ndef compute_metrics(eval_pred):\n\n    predictions, labels = eval_pred\n\n    # Use np.argmax to get the predicted class indices from logits\n    predictions = np.argmax(predictions[0], axis=1)\n    \n\n    # If the labels are one-hot encoded, convert them to class indices\n    if len(labels.shape) > 1:\n        labels = np.argmax(labels, axis=-1)\n\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:17.254197Z","iopub.execute_input":"2023-07-22T06:39:17.255389Z","iopub.status.idle":"2023-07-22T06:39:18.128635Z","shell.execute_reply.started":"2023-07-22T06:39:17.255346Z","shell.execute_reply":"2023-07-22T06:39:18.127749Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d93178cff74a0d99cc4666d3947b87"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_awesome_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model=base_model,\n    args=training_args,\n    train_dataset=train_val_split[\"train\"],\n    eval_dataset=train_val_split[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:39:25.364997Z","iopub.execute_input":"2023-07-22T06:39:25.366132Z","iopub.status.idle":"2023-07-22T06:45:52.213816Z","shell.execute_reply.started":"2023-07-22T06:39:25.366070Z","shell.execute_reply":"2023-07-22T06:45:52.212698Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230722_063957-ok9n16vm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/skt27182/huggingface/runs/ok9n16vm' target=\"_blank\">effortless-vortex-20</a></strong> to <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/skt27182/huggingface' target=\"_blank\">https://wandb.ai/skt27182/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/skt27182/huggingface/runs/ok9n16vm' target=\"_blank\">https://wandb.ai/skt27182/huggingface/runs/ok9n16vm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [384/384 05:21, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.422167</td>\n      <td>0.832540</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.471608</td>\n      <td>0.823182</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.792110</td>\n      <td>0.810868</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.809628</td>\n      <td>0.815630</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=384, training_loss=0.2833700974782308, metrics={'train_runtime': 381.4265, 'train_samples_per_second': 15.961, 'train_steps_per_second': 1.007, 'total_flos': 407560594679904.0, 'train_loss': 0.2833700974782308, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load( \"accuracy\")\n\nbase_model.eval()\nfor batch in tqdm(eval_dataloader):\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = base_model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:45:52.216072Z","iopub.execute_input":"2023-07-22T06:45:52.217322Z","iopub.status.idle":"2023-07-22T06:46:21.645100Z","shell.execute_reply.started":"2023-07-22T06:45:52.217283Z","shell.execute_reply":"2023-07-22T06:46:21.641574Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/96 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"949fff82eeba4435909aa2342a331b27"}},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8325398128386143}"},"metadata":{}}]},{"cell_type":"code","source":"# optimizer = AdamW(base_model.parameters(), lr=2e-05)\n\n# num_epochs = 10\n# num_training_steps = num_epochs * len(train_dataloader)\n\n# lr_scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0, total_iters=num_training_steps)\n\n# print(num_training_steps)\n\n# base_model.to(device)\n\n\n# from tqdm.auto import tqdm\n\n# progress_bar = tqdm(range(num_training_steps))\n\n# base_model.train()\n# for epoch in range(num_epochs):\n#     for batch in train_dataloader:\n#         batch = {k: v.to(device) for k, v in batch.items()}\n#         outputs = base_model(**batch)\n#         loss = outputs.loss\n#         loss.backward()\n\n#         optimizer.step()\n#         lr_scheduler.step()\n#         optimizer.zero_grad()\n#         progress_bar.set_postfix(loss=loss.item())\n#         progress_bar.update(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Test","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\npred = []\n\nbase_model.eval()\nfor batch in test_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = base_model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    pred.append(predictions.reshape(-1).cpu().numpy())\n\n# Convert the list of arrays into a 1D NumPy array\npred = np.concatenate(pred)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:46:59.185341Z","iopub.execute_input":"2023-07-22T06:46:59.185804Z","iopub.status.idle":"2023-07-22T06:47:14.700054Z","shell.execute_reply.started":"2023-07-22T06:46:59.185762Z","shell.execute_reply":"2023-07-22T06:47:14.698878Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"y_pred = pred.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:47:14.702067Z","iopub.execute_input":"2023-07-22T06:47:14.702725Z","iopub.status.idle":"2023-07-22T06:47:14.714308Z","shell.execute_reply.started":"2023-07-22T06:47:14.702683Z","shell.execute_reply":"2023-07-22T06:47:14.713317Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"ids = pd.read_csv('/kaggle/input/test-id/test_id.csv')['id']\n\n# merge ids and predictions\nsubmission = pd.DataFrame(np.concatenate((ids.values.reshape(-1, 1), y_pred.reshape(-1,1)), axis=1), columns=['id', 'target'])\n\n# make id int   \nsubmission['id'] = submission['id'].astype('int')\n\n# make target 0 and 1\nsubmission['target'] = submission['target'].apply(lambda x: 0 if x < 0.5 else 1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:47:14.715878Z","iopub.execute_input":"2023-07-22T06:47:14.716568Z","iopub.status.idle":"2023-07-22T06:47:14.752523Z","shell.execute_reply.started":"2023-07-22T06:47:14.716532Z","shell.execute_reply":"2023-07-22T06:47:14.750741Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:47:14.754650Z","iopub.execute_input":"2023-07-22T06:47:14.755232Z","iopub.status.idle":"2023-07-22T06:47:14.769456Z","shell.execute_reply.started":"2023-07-22T06:47:14.755198Z","shell.execute_reply":"2023-07-22T06:47:14.768493Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rm /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:47:14.770809Z","iopub.execute_input":"2023-07-22T06:47:14.771492Z","iopub.status.idle":"2023-07-22T06:47:15.823746Z","shell.execute_reply.started":"2023-07-22T06:47:14.771460Z","shell.execute_reply":"2023-07-22T06:47:15.822390Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nrm: cannot remove '/kaggle/working/submission.csv': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save submission\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:47:15.825780Z","iopub.execute_input":"2023-07-22T06:47:15.832021Z","iopub.status.idle":"2023-07-22T06:47:15.852517Z","shell.execute_reply.started":"2023-07-22T06:47:15.831982Z","shell.execute_reply":"2023-07-22T06:47:15.851363Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}